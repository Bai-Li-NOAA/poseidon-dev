---
output: 
  md_document:
    variant: gfm
---

### NOBA Cod atlantisom2ss conversion
#### Workflow
- Put `NOBA_sacc_30` folder (Atlantisom output) in the `NOBA_cod_files/` folder
- Modify `NOBACOD_atlantisom2SS.R` to convert Atlantisom output to SS input. 

  - We have finished conversion for all SS input files.
  - The new SS input files can be save in the `NOBA_cod_files/output/atlantis2ss` folder.

- The SS model still did not converge after trying different stock-recruitment models, input values of steepness and standard deviation of the recruitment deviation in log space, and selectivity patterns. The residuals between observed and estimated age compositions were large. 

- After removing survey age composition data from the input file, SS had a better final gradient value of 0.00019. The expected landings, landing age compositions, and survey indices match well with the true values from Atlantis. However, the estimated biomass, spawning stock biomass, recruitment, and fishing mortality still did not line up with the true values from Atlantis.
```{r, warning = FALSE, message = FALSE, fig.height = 6, echo=FALSE}
# remotes::install_github("r4ss/r4ss")
library(r4ss)
library(here)
library(tidyr)
require(dplyr)
library(ggplot2)
library(ggforce)
library(ggthemes)

# SS output ---------------------------------------------------------------

# SS output path
mydir <- here("NOBA_cod_files", "output", "atlantis2ss")
# mydir <- here("NOBA_cod_files", "output", "q")
# read the model output and print diagnostic messages 
ss_list <- SS_output(dir = mydir, 
                     verbose = FALSE,
                     printstats = FALSE)

# plots the SS results
# SS_plots(ss_list)


# Atlantis output ---------------------------------------------------------
# Set up d.name and scenario.name
d.name <- here::here("NOBA_cod_files", "NOBA_sacc_30")
scenario.name <- "nordic_runresults_01"

# Atlantis OM truth data
truth <- get(load(file.path(file.path(d.name, "nordic_runresults_01run_truth.RData"))))
omlist_ss <- readRDS(file=file.path(d.name, "nordic_runresults_01omlist_ss.rds"))

# Set species name
species <- c("North_atl_cod")
species_code <- "NCO"

# Number of years of data to pull (From the project page: https://sgaichas.github.io/poseidon-dev/NOBAcod2.html#)
nyears <- omlist_ss$runpar$nyears #144

# Atlantis initialization period in years
burnin <- 0

# fishery output: learned the hard way this can be different from ecosystem outputs
fstepperyr <- if(omlist_ss$runpar$outputstepunit=="days") 365/omlist_ss$runpar$toutfinc #5

noutsteps <- omlist_ss$runpar$tstop/omlist_ss$runpar$outputstep #720
timeall <- c(0:noutsteps)
stepperyr <- if(omlist_ss$runpar$outputstepunit=="days") 365/omlist_ss$runpar$toutinc #5
midptyr <- round(median(seq(0,stepperyr))) #2

timestep <- stepperyr #5

#The last timestep to sample
total_sample <- noutsteps-1 #719
# same time dimensioning parameters as in surveycensus.R
#Vector of indices of catch in numbers to pull (by timestep to sum)
fish_sample_full <- c(0:total_sample)  #total_sample defined in sardinesurvey.R #0-719
fish_burnin <- burnin*fstepperyr+1 #1
fish_nyears <- nyears*fstepperyr #144*5=720
fish_times <- fish_sample_full[fish_burnin:(fish_burnin+fish_nyears-1)] #0-719
fish_timesteps <- seq(fish_times[fstepperyr], max(fish_times), by=fstepperyr) #last timestep: 4, 9, ...719
#fish_years <- unique(floor(fish_times/fstepperyr)+1) # my original [1-144]
fish_years <- unique(floor(fish_times/fstepperyr)) #from Christine's new sardine_config.R [0-143]

fishtime <- fish_times #0-719


fitstartyr <- 40
fitendyr <- 79  #Fishery catch-at-age and weight-at-age data year range: 30-79

#Number of years of data to pull
nyears <- omlist_ss$runpar$nyears #144
total_sample <- omlist_ss$runpar$tstop/omlist_ss$runpar$outputstep #720
stepperyr <- if(omlist_ss$runpar$outputstepunit=="days") 365/omlist_ss$runpar$toutinc #5

atlantis_full <- c(0:total_sample)  
mod_burnin <- fitstartyr*stepperyr+1 #201
fit_nyears <- fitendyr-fitstartyr+1 #40
fit_ntimes <- fit_nyears*stepperyr #200
fittimes <- atlantis_full[mod_burnin:(mod_burnin+fit_ntimes-1)] #200-399
fit_timesteps <- seq(fittimes[stepperyr], max(fittimes), by=stepperyr) #last timestep
fit_years <- unique(floor(fittimes/stepperyr)) #from Christine's new sardine_config.R #40-79
fittimes.days <- fittimes*73 #14600, 14673, ...29127


# Comparisons -------------------------------------------------------------

folder_path <- here("atlantisoutput", "NOBA_sacc_30")

# Fall biomass
fallB <- readRDS(file.path(d.name, paste0(scenario.name,"_BTS_fall_allbox_effic1surveyB.rds")))

fallB_ss <- fallB[[1]] %>%
  filter(species == "North_atl_cod")

plotB <-ggplot() +
  geom_line(data=fallB_ss, aes(x=(time-3)/stepperyr,y=atoutput, color="True fall survey B"), 
            alpha = 10/10) +
  geom_point(data=ss_list$cpue[which(ss_list$cpue$Fleet==2),], aes(x=Yr,y=Exp*1000, color="SS3 Est B"),
             alpha = 10/10) + 
  theme_tufte() +
  theme(legend.position = "top") +
  labs(colour=scenario.name) 

plotB +
  facet_wrap(~species, scales="free") 


# Spring biomass
springB <- readRDS(file.path(d.name, paste0(scenario.name,"_BTS_spring_allbox_effic1surveyB.rds")))

springB_ss <- springB[[1]] %>%
  filter(species == "North_atl_cod")

plotB <-ggplot() +
  geom_line(data=springB_ss, aes(x=(time-1)/stepperyr,y=atoutput, color="True spring survey B"), 
            alpha = 10/10) +
  geom_point(data=ss_list$cpue[which(ss_list$cpue$Fleet==3),], aes(x=Yr,y=Exp*1000, color="SS3 Est B"),
             alpha = 10/10) + 
  theme_tufte() +
  theme(legend.position = "top") +
  labs(colour=scenario.name)

plotB +
  facet_wrap(~species, scales="free") 

# Landings
trueL <- read.table(file.path(folder_path, "nordic_runresults_01Catch.txt"), header = TRUE)
trueL_ss <- trueL[which(as.integer(trueL$Time/365) %in% fit_years), species_code]

ssL <- ss_list$timeseries$`sel(B):_1`[ss_list$timeseries$Yr %in% fit_years]*1000

plot(trueL_ss, ylim=range(trueL_ss, ssL), 
     xlab="Year", ylab="Landings (t)")
lines(ssL)
legend("topright",
       c("True L", "SS3 Est L"),
       pch=c(1, NA), 
       lty=c(NA, 1),
       bty="n")

# Biomass
trueB <- read.table(file.path(folder_path, "nordic_runresults_01BiomIndx.txt"), header = TRUE)

trueB_ss <- trueB[which(as.integer(trueB$Time/73) %in% fit_timesteps), species_code]

ssB <- ss_list$timeseries$Bio_all[ss_list$timeseries$Yr %in% fit_years]*1000

par(mar = c(5, 4, 4, 4) + 0.3) 
plot(trueB_ss, 
     xlab="Year", ylab="True Biomass (t)")
par(new = TRUE)
plot(ssB, type = "l", axes = FALSE, bty = "n", xlab = "", ylab = "")
axis(side=4, at = pretty(range(ssB)))
mtext("SS Est Biomass (t)", side=4, line=3)
legend("topright",
       c("True B", "SS3 Est B"),
       pch=c(1, NA), 
       lty=c(NA, 1),
       bty="n")

# Spawning stock biomass
trueSSB <- read.table(file.path(folder_path, "nordic_runresults_01SSB.txt"), header = TRUE)
trueSSB_ss <- trueSSB[which(as.integer(trueSSB$Time/73) %in% fit_timesteps), species_code]

ssSSB <- ss_list$timeseries$SpawnBio[ss_list$timeseries$Yr %in% fit_years]*1000

par(mar = c(5, 4, 4, 4) + 0.3) 
plot(trueSSB_ss, 
     xlab="Year", ylab="True SSB (t)")
par(new = TRUE)
plot(ssSSB, type = "l", axes = FALSE, bty = "n", xlab = "", ylab = "")
axis(side=4, at = pretty(range(ssSSB)))
mtext("SS Est SSB (t)", side=4, line=3)
legend("topright",
       c("True SSB", "SS3 Est SSB"),
       pch=c(1, NA), 
       lty=c(NA, 1),
       bty="n")

# Recruitment

nitro <- merge(omlist_ss$biol$kwsr, omlist_ss$biol$kwrr, by = "1")
names(nitro) <- c("Code", "KWSR", "KWRR")

nitro <- nitro %>%
  group_by(Code) %>%
  mutate(Nsum = sum(KWSR, KWRR))
truerec <- omlist_ss$YOY_ss %>% 
  pivot_longer(-Time, names_to = "Code", values_to = "recwt") %>%
  mutate(Code = gsub("\\.0", "", Code)) %>%
  filter(Time>0) %>% # this output not meaningful
  filter(Time %in% seq(365, max(Time), by=365)) %>%
  left_join(omlist_ss$funct.group_ss[, c("Code", "Name")]) %>%
  left_join(nitro) %>%
  mutate(recnums = (recwt * 50000000.0 / omlist_ss$biol$redfieldcn) / Nsum) %>%
  group_by(Name) %>%
  mutate(meanrecnums = mean(recnums))

truerec_ss <- truerec[truerec$Name==species,]

plotR <-ggplot() +
  geom_line(data=truerec_ss, aes(x=Time/365,y=recnums, color="True R"), 
            alpha = 10/10) +
  geom_point(data=ss_list$timeseries, aes(x=Yr,y=(Recruit_0*1000), color="SS3 Est R"),
             alpha = 10/10) +
  theme_tufte() +
  theme(legend.position = "top") +
  labs(colour=scenario.name)

plotR 

ssR <- ss_list$timeseries$Recruit_0[ss_list$timeseries$Yr %in% fit_years]*1000

par(mar = c(5, 4, 4, 4) + 0.3) 
plot(fit_years, truerec_ss$recnums[which((truerec_ss$Time/365) %in% fit_years)], 
     xlab="Year", ylab="True R")
par(new = TRUE)
plot(fit_years, ssR, type = "l", axes = FALSE, bty = "n", xlab = "", ylab = "")
axis(side=4, at = pretty(range(ssR)))
mtext("SS Est R", side=4, line=3)
legend("topright",
       c("True R", "SS3 Est R"),
       pch=c(1, NA), 
       lty=c(NA, 1),
       bty="n")

# Fishing mortality
file.mort <- file.path(folder_path, "nordic_runresults_01Mort.txt")

mortish <- read.table(file.mort, header = TRUE)

relF_ss <- mortish %>%
  select(Time, relF = paste0(species_code, ".F"))

names(ss_list$timeseries)[19]<-"Fmort"

plotF <-ggplot() +
  geom_line(data=relF_ss, aes(x=Time/365, y=relF, color="True F"), 
            alpha = 10/10) +
  geom_point(data=ss_list$timeseries, aes(x=Yr,y=Fmort, color="SS3 Est F"),
             alpha = 10/10) + 
  theme_tufte() +
  theme(legend.position = "top") +
  labs(colour=scenario.name)

plotF 

ssF <- ss_list$timeseries$Fmort[ss_list$timeseries$Yr %in% fit_years]
par(mar = c(5, 4, 4, 4) + 0.3) 
plot(fit_years, relF_ss$relF[(relF_ss$Time/365) %in% fit_years], 
     xlab="Year", ylab="True F")
par(new = TRUE)
plot(fit_years, ssF, type = "l", axes = FALSE, bty = "n", xlab = "", ylab = "")
axis(side=4, at = pretty(range(ssF)))
mtext("SS Est F", side=4, line=3)
legend("topright",
       c("True F", "SS3 Est F"),
       pch=c(1, NA), 
       lty=c(NA, 1),
       bty="n")

# R over SSB
plot(trueSSB_ss, 
     ssR,
     xlab="True SSB", 
     ylab="True R")



```

### NOBA Cod SAM2SS conversion
In this example, we convert NOBA Cod State-space assessment model (SAM) inputs to Stock Synthesis (SS) inputs and compare the outputs from the two packages.

#### Install and library packages
```{r, warning = FALSE, message = FALSE}
# install.packages("here")
# 
# install_64bit <- TRUE
# 
# if (install_64bit) {
#   args <- c("--no-multiarch")
# } else {
#   args <- c("")
# }
# 
# devtools::install_github("fishfollower/SAM/stockassessment", INSTALL_opts = args)
# 
# remotes::install_github("r4ss/r4ss", branch = "development")
# 
# remotes::install_github("Bai-Li-NOAA/saconvert") # Need to install "kellijohnson-NOAA/saconvert" after doing pull request.
# 
# remotes::install_github("nmfs-general-modeling-tools/nmfspalette")

library(here)
library(stockassessment) # For using SAM
library(r4ss) # For using SS
library(saconvert)
library(nmfspalette)
```

#### Read SAM input data and run SAM
```{r, warning = FALSE, message = FALSE}
sam_input_path <- here::here("NOBA_cod_files", "NEAcod-2020", "data")

# Read in data files
regdat <- grep(".dat",list.files(sam_input_path))
filenames_ICES <- list.files(sam_input_path)[regdat]

#All objects are now on input_file_list
input_file_list <- lapply(file.path(sam_input_path,filenames_ICES), read.ices)
names(input_file_list) <- gsub(".dat","",filenames_ICES)

#Load into function environment as objects
list2env(input_file_list, environment())

# Create a collected data object
sam_dat <- setup.sam.data(
  surveys = survey,
  residual.fleet = cn,
  prop.mature = mo,
  stock.mean.weight = sw,
  catch.mean.weight = cw,
  dis.mean.weight = dw,
  land.mean.weight = lw,
  prop.f = pf,
  prop.m = pm,
  natural.mortality = nm,
  land.frac = lf
)

# Generate a default/minimalistic model configuration
sam_conf <- defcon(sam_dat)

# Generate default initial values for all our model parameters
sam_par <- defpar(sam_dat, sam_conf)

# Fit the SAM model
sam_fit <- sam.fit(sam_dat, sam_conf, sam_par, silent=TRUE)

```


#### Plot SAM fits
```{r, fig.height = 6, sam_fit}
par(mfrow = c(1, 1))
ssbplot(sam_fit)
fbarplot(sam_fit)
recplot(sam_fit)
catchplot(sam_fit)
```

#### Convert SAM inputs to SS inputs
```{r, warning = FALSE, message = FALSE}
# Set up two scenarios
# Scenario A: use selectivity pattern 20 and F method 3 in SS
# Scenario B: use selectivity pattern 20 and F method 2 in SS

scenario_path <- c("A", "B")
slx_pattern <- c(20, 20)
f_method <- c(3, 2)


for (scenario_id in seq_along(scenario_path)){
  output_path <- here::here("NOBA_cod_files", "output", scenario_path[scenario_id])
  if(!dir.exists(output_path)) dir.create(output_path)
  
  saconvert::ICES2SS(
    user.wd = sam_input_path,
    user.od = output_path,
    ices.id = "",
    tvslx = FALSE,
    ages = NULL,
    nsexes = 1, # 1: one sex; 2: two sex; -1: one sex and multiply the spawning biomass by the fraction female in the control file
    forN = 2,
    q.extra.se = FALSE,
    q.float = FALSE,
    slx = slx_pattern[scenario_id],
    f.method = f_method[scenario_id]
  ) # steep.init: http://sedarweb.org/docs/wpapers/SEDAR19_DW_06_SteepnessInference.pdf
  
}
```

#### Compare SAM outputs and SS outputs
```{r, warning = FALSE, message = FALSE, fig.height = 6, sam_ss_comparison}
sam_output <- data.frame(
  "Year" = c(sam_dat$years),
  "SSB" = exp(sam_fit$sdrep$value[names(sam_fit$sdrep$value) %in% "logssb"]),
  "Recruits" = exp(sam_fit$sdrep$value[names(sam_fit$sdrep$value) %in% "logR"]),
  "F" = exp(sam_fit$sdrep$value[names(sam_fit$sdrep$value) %in% "logfbar"]),
  "Catch" = c(exp(sam_fit$sdrep$value[names(sam_fit$sdrep$value) %in% "logCatch"]), NA)
)

ss_output <- list()
for (scenario_id in seq_along(scenario_path)){
  ss_output_path <- here::here("NOBA_cod_files", "output", scenario_path[scenario_id])
  ss_output_data <- SS_output(dir = ss_output_path, verbose = F, printstats = F)
  ss_output[[scenario_id]] <- data.frame(
    "Year" = sam_output$Year,
    "SSB" = ss_output_data$timeseries$SpawnBio[ss_output_data$timeseries$Yr %in% sam_output$Year],
    "Recruits" = ss_output_data$timeseries$Recruit_0[ss_output_data$timeseries$Yr %in% (sam_output$Year-1)],
    "F" = ss_output_data$timeseries$`F:_1`[ss_output_data$timeseries$Yr %in% sam_output$Year],
    "Catch" = ss_output_data$timeseries$`sel(B):_1`[ss_output_data$timeseries$Yr %in% sam_output$Year]
  )
}

var <- c("SSB", "Recruits", "F", "Catch")
var_label <- c("SSB", "Recruits (Age 3)", expression(F[9-13]), "Catch (in weight)")
colors <- nmfspalette::nmfs_palette("regional web")(length(scenario_path)+1)

par(mfrow = c(2, 2), mar = c(4, 4, 1, 1))

for (i in seq_along(var)){
  plot(NA,
       type="n",
       xlim = range(sam_output$Year),
       ylim = range(sam_output[, var[i]], na.rm = T),
       xlab = "Year",
       ylab = var_label[i]
  )
  lines(sam_output$Year,
        sam_output[, var[i]],
        lty=1,
        col=colors[1])
  for (j in seq_along(scenario_path)){
    lines(ss_output[[j]]$Year,
          ss_output[[j]][, var[i]],
          lty=j+1,
          col=colors[j+1])
  }
}

legend("top", 
       c("SAM", paste("SS_", scenario_path)),
       lty = seq_along(colors),
       col = colors,
       bty="n")
```


### Resources
  - [SAM GitHub repository](https://github.com/fishfollower/SAM)
	- Aldrin et al., 2020: [The specification of the data model part in the SAM model matters](https://www.sciencedirect.com/science/article/pii/S0165783620301028#bib0020)
	- Nielsen and Berg, 2014: [Estimation of time-varying selectivity in stock assessments using state-space models](https://www.sciencedirect.com/science/article/abs/pii/S0165783614000228?via%3Dihub)
	- Berg and Nielsen, 2016: [Accounting for correlated observations in an age-based state-space stock assessment model](https://academic.oup.com/icesjms/article/73/7/1788/2458744)
	- [ICES Report of the Arctic Fisheries Working Group (AFWG)](https://www.ices.dk/sites/pub/Publication%20Reports/Expert%20Group%20Report/acom/2018/AFWG/00-AFWG%202018%20Report.pdf)
	
