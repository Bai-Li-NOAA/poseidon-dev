---
title: "WritingSSfiles"
author: "Christine Stawitz"
date: "May 14, 2019"
output: html_document
---

```{r setup, include=FALSE}
require(here)
require(reshape2)
require(dplyr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/chris/Documents/GitHub/atlantisom/")
```

## Introduction

This page discusses reading in an existing stock assessment file and replacing the data values with those from the `atlantisom` package. To read in the Stock Synthesis files, first ensure you have the latest version of `r4ss`

```{r packages, eval=FALSE}
devtools::install_github("r4ss/r4ss", dependencies = FALSE)
```

## Sardine example

Dummy files are in the package directory; use `r4ss` to load the dummy data file

```{r readdata, echo=FALSE}
require(r4ss)
#Read in sardine data file
sardine.data <- r4ss::SS_readdat_3.30("./inst/extdata/Sardine_SS_files/sardEM_3_3.dat")
```

Below, we can see the structure of the catch and CPUE data
```{r}
names(sardine.data$catch) <- names(sardine.data$CPUE)

sardine.data$CPUE
```

We can next look at age composition data
```{r}
sardine.data$agecomp

sardine.data$lencomp
```

We may also need to access or modify the setup variables before the data matrices.

```{r}
#CPUE units, SD and error structure
sardine.data$CPUEinfo

#Number of length bins
sardine.data$N_lbins

#Length bin method
sardine.data$Lbin_method

#Vector of age bins
sardine.data$agebin_vector

```

## Writing index data
To edit index data, use the `atlantisom` sampling functions to extract survey biomass and numbers. These can then be written using the `SS_write_CPUE` function.

```{r}
results <- get(load("outputCCV3run_truth.RData"))
devtools::load_all()
species=c("Pacific_sardine")

#Sample all boxes
boxes <- unique(results$nums$polygon)

#Efficiency of the survey
effic <- data.frame(species=species, efficiency=0.5)

# Assume uniform selectivity
sel<- data.frame(species=rep(species,10),
               agecl=c(1:10),
              selex=rep(1,10))

#Sample survey - 3rd timestep simulates a summer survey
survey_out <- create_survey(dat=results$nums, time=seq(3,495,by=5), species=species, boxes=boxes, effic=effic, selex=sel)

#Need to replace with interp function
wtAtAge <- data.frame(species=rep("Pacific_sardine",10),
                agecl=1:10,
                wtAtAge=c(0.0542, 0.0837,	0.1103,	0.1323,	0.1497,	0.163,	0.1729,	0.1801,	0.1854,	0.1941))
cv <- data.frame(species="Pacific_sardine", cv=c(0.2))

#Sample survey biomass
survObsBiom <- sample_survey_biomass(dat=survey_out,cv=cv,wtAtAge)

sardine.catch <-  create_fishery_subset(dat = results$catch,
                                         time = seq(3,495,by=5),
                                         species = species,
                                         boxes = boxes)

#Sample catch in numbers
sardine.catch.total <- sardine.catch %>%
  group_by(time) %>%
  summarise(catch=sum(atoutput))

nyears <- 50
burnin <- 30

#Test writing CPUE in biomass
  sardine.data <- SS_write_ts(ss_data_list = sardine.data,
                ts_data = list(survObsBiom$atoutput[burnin:(burnin+nyears-1)],
                  sardine.catch.total$catch),
                CVs = c(0.2,0.2),
                data_years = list((survObsBiom$time[burnin:(burnin+nyears-1)]-3)/5+1, 
                            (sardine.catch.total$time-3)/5+1),
                sampling_month = list(rep(7,nyears),
                                      rep(1,20)),
                units = c("biomass","numbers"),
                data_type=c("CPUE","catch"),
                fleets = c(2,1))

```

## Writing age composition data 

```{r}
#Set effective sample size for age compositions
effN <- 1000
highEffN <- data.frame(species=species, effN=rep(effN, length(species)))

#Sample fish for age composition
age_comp_data <- sample_fish(survey_out, highEffN)

age_comp_data

#Group age composition data by time
require(dplyr)
age_comp_proportion <- age_comp_data %>%
  group_by(time) %>%
  mutate(comp = atoutput/sum(atoutput))

#Get the age bins
age_bin_names <- names(sardine.data$agecomp)[10:length(names(sardine.data$agecomp))]
age_bins <- sub("a","",age_bin_names)

#Change data format into flat structure
age_comp_proportion$id <- rep(age_bins,
                              each = nrow(age_comp_proportion)/length(age_bins))

unmelt <- dcast(data = age_comp_proportion,
                formula = time ~agecl,
                value.var = "comp")
age_comp_flat<- cbind(unmelt[order(unmelt$time),],
                      rep(effN,nrow(unmelt)))
names(age_comp_flat)[ncol(age_comp_flat)] <- "nsamp"

## Write age composition data
sardine.data <- SS_write_comps(ss_data_list = sardine.data,
               comp_matrix = list(age_comp_flat[burnin:(burnin+nyears-1),]),
               data_rows = list(sardine.data$styr:(sardine.data$styr+nyears-1)),
               sampling_month = list(rep(7,nyears)),
               data_type = c("agecomp"),
               fleet_number = c(1),
               bins = list(age_bins),
               caal_bool = c(FALSE))
sardine.data$agecomp

```


## Setting up sardine EM
For the sardine EM, we want conditional age-at-length (CAAL) and length composition data only. So we use the same function with our matrices of length and CAAL comp data to write to the data file.

```{r}
# aggregate true resn per survey design
survey_aggresnstd <- aggregateDensityData(dat = results$resn,
                                          time = unique(results$nums$time),
                                          species = species,
                                          boxes = boxes)

# aggregate true structn per survey design
survey_aggstructnstd <- aggregateDensityData(dat = results$structn,
                                             time = unique(results$nums$time),
                                             species = species,
                                             boxes = boxes)

ss_structnstd <- sample_fish(survey_aggstructnstd,
                             effN,
                             sample=FALSE)
ss_resnstd <- sample_fish(survey_aggresnstd,
                          effN,
                          sample=FALSE)

#Extract length composition data
ss_length_stdsurv <- calc_age2length(structn = ss_structnstd,
                                     resn = ss_resnstd,
                                     nums = age_comp_data,
                                     biolprm = results$biolprm, fgs = results$fgs,
                                     CVlenage = 0.1, remove.zeroes=TRUE)

#Check length compositions match age compositions
ss_length_stdsurv$natlength %>%
  group_by(time,agecl) %>%
  summarise(sum(atoutput))

len_comp_data <- ss_length_stdsurv$natlength

```

Once we have the natlength matrix, we can munge the data into the proper CAAL and length bin format for SS


```{r}

#We want to aggregate the data by year 
caal_comp_proportion <- len_comp_data %>%
  group_by(time) %>%
  mutate(comp = round(atoutput/sum(atoutput),4)) %>%
  select(agecl, time, atoutput, lower.bins,
         upper.bins,comp)

#Use dcast to turn the data from long to wide format
unmelt_caal <- dcast(data = caal_comp_proportion,formula = time + lower.bins + upper.bins~agecl,value.var = "comp")
unmelt_caal[is.na(unmelt_caal)] <- 0

#Add nsamp column
sample_size <- apply(unmelt_caal[,(4:ncol(unmelt_caal))], FUN=sum, MARGIN=1)
caal_comp_flat<- cbind(unmelt_caal[order(unmelt_caal$time),],sample_size)
names(caal_comp_flat)[ncol(caal_comp_flat)] <- "nsamp"

#remove burnin
caal_comp_final <- filter(caal_comp_flat,
                         time %in% burnin:(burnin+nyears-1))

len_comp_proportion <- len_comp_data %>%
  group_by(time, lower.bins, upper.bins) %>%
  summarise(lencomp = sum(atoutput))

#Do the same for length composition
unmelt_len <- dcast(data = len_comp_proportion,formula = time ~lower.bins,value.var = "lencomp")
unmelt_len[is.na(unmelt_len)] <- 0

#Add over age classes to get sample size
sample_size <- apply(unmelt_len[,(2:ncol(unmelt_len))], FUN=sum, MARGIN=1)
len_comp_flat<- cbind(unmelt_len[order(unmelt_len$time),],sample_size)
names(len_comp_flat)[ncol(len_comp_flat)] <- "nsamp"

#remove burnin
len_comp_final <- filter(len_comp_flat,
                         time %in% burnin:(burnin+nyears-1))

length_bins <- as.integer(names(len_comp_final))
length_bins <- length_bins[!is.na(length_bins)]

# Write CAAL and length composition data
sardine.data <- SS_write_comps(ss_data_list = sardine.data,
                               comp_matrix = list(caal_comp_final,len_comp_final),
                               data_rows = list(caal_comp_final$time,len_comp_final$time),
                               sampling_month = list(rep(7,nrow(caal_comp_final)),
               rep(7,nrow(len_comp_final))),
                               data_type = c("agecomp", "lencomp"),
                               fleet_number = c(1,1),
                               bins = list(age_bins, length_bins),
                               caal_bool = c(TRUE, FALSE))

head(sardine.data$lencomp)
head(sardine.data$agecomp)

#Change length bin structure to match atlantis data
sardine.data$lbin_vector <- length_bins

#Set lbin_method to 1 - this makes the population length bins match the data bins 
#When lbin_method==1, we just comment out the binwidth, minimum, and maximum size arguments since they aren't used
sardine.data$lbin_method <- 1
sardine.data$binwidth <- "#"
sardine.data$minimum_size <- "#"
sardine.data$maximum_size <- "#"

#Change minimum sample size to 0.001 for CAAL data (SS won't let it go lower than this)
sardine.data$age_info$minsamplesize <- rep(0.001,2)

SS_writedat_3.30(sardine.data, outfile = "./inst/extdata/Sardine_SS_files/sardEM_3_3.dat",
                 overwrite=TRUE)
```

