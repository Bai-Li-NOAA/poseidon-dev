---
title: "Testing atlantisom: generate census length comps for Norwegian Barents Sea Atlantis"
author: "Sarah Gaichas and Christine Stawitz"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
bibliography: "packages.bib"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'knitr', 'rmarkdown', 'tidyr', 'dplyr', 'ggplot2',
  'data.table', 'here', 'ggforce', 'ggthemes'
), 'packages.bib')
```

## Introduction

This page has visualizations for the NOBA model example, CERES Global Sustainability. For full explanation of methods, see the file linked at the beginning of each section. 

```{r message=FALSE, warning=FALSE}
library(tidyr)
require(dplyr)
library(ggplot2)
library(data.table)
library(here)
library(ggforce)
library(ggthemes)
library(atlantisom)
```

```{r initialize}

initCCA <- FALSE
initNEUS <- FALSE
initNOBA <- TRUE

if(initCCA) source(here("config/CCConfig.R"))

if(initNEUS) source(here("config/NEUSConfig.R"))

if(initNOBA) source(here("config/NOBAConfig.R"))

```

```{r get_names, message=FALSE, warning=FALSE}
#Load functional groups
funct.groups <- load_fgs(dir=d.name,
                         file_fgs = functional.groups.file)
#Get just the names of active functional groups
funct.group.names <- funct.groups %>% 
  filter(IsTurnedOn == 1) %>%
  select(Name) %>%
  .$Name

```

```{r load_Rdata, message=FALSE, warning=FALSE}

if(initCCA) {
  truth.file <- "outputCCV3run_truth.RData"
  load(file.path(d.name, truth.file))
  truth <- result
} 

if(initNEUS) {
  truth.file <- "outputneusDynEffort_Test1_run_truth.RData" 
  load(file.path(d.name, truth.file))
  truth <- result
}

if(initNOBA){
  truth.file <- "outputnordic_runresults_01run_truth.RData" 
  load(file.path(d.name, truth.file))
  truth <- result
}

```

## Simulate a survey part 4: sample for length composition

Full methods are explained [here](https://sgaichas.github.io/poseidon-dev/TrueLengthCompTest.html).

The following settings should achieve a survey that samples all Atlantis model output timesteps, all fish and shark species, and all model polygons, with perfect efficiency and full selectivity for all ages: 

```{r census-spec, message=FALSE, warning=FALSE, echo=TRUE}

# should return a perfectly scaled survey 
effic1 <- data.frame(species=funct.group.names,
                     efficiency=rep(1.0,length(funct.group.names)))

# should return all lengths fully sampled (Atlantis output is 10 age groups per spp)
selex1 <- data.frame(species=rep(funct.group.names, each=10),
                     agecl=rep(c(1:10),length(funct.group.names)),
                     selex=rep(1.0,length(funct.group.names)*10))

# should return all model areas
boxpars <- load_box(d.name, box.file)
boxall <- c(0:(boxpars$nbox - 1))

# generalized timesteps all models
runpar <- load_runprm(d.name, run.prm.file)
noutsteps <- runpar$tstop/runpar$outputstep
stepperyr <- if(runpar$outputstepunit=="days") 365/runpar$toutinc

timeall <- c(0:noutsteps)
  
# define set of species we expect surveys to sample (e.g. fish only? vertebrates?)
# for ecosystem indicator work test all species, e.g.
survspp <- funct.group.names 

# for length and age groups lets just do fish and sharks
# NOBA model has InvertType, changed to GroupType in file, but check Atlantis default
if(initNOBA) funct.groups <- rename(funct.groups, GroupType = InvertType)

survspp <- funct.groups$Name[funct.groups$IsTurnedOn==1 &
                           funct.groups$GroupType %in% c("FISH", "SHARK")]

```

Here we use `create_survey` on the numbers output of `run_truth` to create the survey census of age composition. 

```{r stdsurveyNbased, echo=TRUE}

survey_testNall <- create_survey(dat = truth$nums,
                                 time = timeall,
                                 species = survspp,
                                 boxes = boxall,
                                 effic = effic1,
                                 selex = selex1)

# consider saving this interim step if it takes a long time go generate


```


```{r truecohortagecomp}
# what is true composition? need annual by species, use code from sample_fish
# do tidyly
dat2 <- survey_testNall %>%
  group_by(species, agecl, time) %>%
  summarize(numAtAge = sum(atoutput))

totN <- dat2 %>%
  group_by(species, time) %>%
  summarize(totN = sum(numAtAge))

dat2totN <- merge(dat2, totN)

# ageclcomp <- ggplot(dat2totN, aes(x=agecl, y=numAtAge/totN, col=time)) +
#   geom_point()
# 
# ageclcomp + facet_wrap_paginate(~species, ncol=3, nrow = 3, page = 1, scales="free")
# ageclcomp + facet_wrap_paginate(~species, ncol=3, nrow = 3, page = 2, scales="free")
# ageclcomp + facet_wrap_paginate(~species, ncol=3, nrow = 3, page = 3, scales="free")
# ageclcomp + facet_wrap_paginate(~species, ncol=3, nrow = 3, page = 4, scales="free")

```

Then we use the `sample_fish` function with very high effN and compare to true annual age comp calculated above as a test, which matches as we have shown [here](https://sgaichas.github.io/poseidon-dev/TrueLengthAgeCompTest.html).

The following gets both numbers and weights to get the length comp, and ultimately the weight at age for use in assessments. 

First we subset the nums, resn, and structn components of `run_truth` using the same `create_survey` design selecting boxes, time, and species. We need only apply survey efficiency and selectivity to nums, however (done above), so we apply `aggregateDensityData` here. 

```{r aggdens, echo=TRUE}

# aggregate true resn per survey design
survey_aggresnall <- aggregateDensityData(dat = truth$resn,
                                 time = timeall,
                                 species = survspp,
                                 boxes = boxall)

# aggregate true structn per survey design
survey_aggstructnall <- aggregateDensityData(dat = truth$structn,
                                 time = timeall,
                                 species = survspp,
                                 boxes = boxall)

```

Now we should have inputs to `sample_fish` on the same scale, and they need to be aggregated across boxes into a single biological sample for the whole survey. We are not maintaining spatial structure in sampling because it isn't used in most assessments.

To do the proper aggregation and not apply the multinomial sampling to the density data, I rewrote `sample_fish` to apply the median if `sample=FALSE` in the function call. 

```{r censussurvey-samplefish, warning=FALSE, message=FALSE, echo=TRUE}

# this one is high but not equal to total for numerous groups
effNhigh <- data.frame(species=survspp, effN=rep(1e+8, length(survspp)))

# apply default sample fish as before to get numbers
numsallhigh <- sample_fish(survey_testNall, effNhigh)

#dont sample these, just aggregate them using median
structnall <- sample_fish(survey_aggstructnall, effNhigh, sample = FALSE)

resnall <-  sample_fish(survey_aggresnall, effNhigh, sample = FALSE)

```

Select a single species for testing. Generating length composition for a single species should take just a few minutes to run. Update: for NOBA with many output timesteps, even a single species took 15-20 minutes.

```{r singlespp-lengthcomp, echo=TRUE}

# this should still represent a census but with polygon and layer aggregated
# WARNING: selecting a species by name is hardcoded for a particular model

ss_numsallhigh <- numsallhigh[numsallhigh$species == "Green_halibut",]
ss_structnall <- structnall[structnall$species == "Green_halibut",]
ss_resnall <- resnall[resnall$species == "Green_halibut",]

ss_length_censussurvsamp <- calc_age2length(structn = ss_structnall,
                                 resn = ss_resnall,
                                 nums = ss_numsallhigh,
                                 biolprm = truth$biolprm, fgs = truth$fgs,
                                 CVlenage = 0.1, remove.zeroes=TRUE)

```


This gives annual length comps:

```{r ss-lengthsamp1-test}

lfplot <- ggplot(ss_length_censussurvsamp$natlength, aes(upper.bins)) +
  geom_bar(aes(weight = atoutput)) +
  theme_tufte()

lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 1, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 2, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 3, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 4, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 5, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 6, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 7, scales="free_y")

# try dir = "v" option for vertical lf comparisons

```

## Run for all species then SAVE

This code block can take hours (5+ for CCA and 18+ for NOBA) to run, so be prepared, but then the saved file can be read back in to have length comps for all surveyed species. For a normal survey query we would have only one output timestep per year, which should save some time.

```{r allspplength, echo=TRUE, eval=FALSE}

length_censussurvsamp <- calc_age2length(structn = structnall,
                                 resn = resnall,
                                 nums = numsallhigh,
                                 biolprm = truth$biolprm, fgs = truth$fgs,
                                 CVlenage = 0.1, remove.zeroes=TRUE)

#save for later use, takes a long time to generate
saveRDS(length_censussurvsamp, file.path(d.name, paste0(scenario.name, "length_censussurvsamp.rds")))

```

Read it back in:

```{r loadlengthcomp, echo=TRUE, eval=FALSE}

length_censussurvsamp <- readRDS(file.path(d.name, paste0(scenario.name, "length_censussurvsamp.rds")))

```

Demo plots for other species:

```{r moreplots, echo=TRUE, eval=FALSE}

ss_length_censussurvsamp <- length_censussurvsamp$natlength %>%
  filter(species == "Norwegian_ssh")

lfplot <- ggplot(ss_length_censussurvsamp, aes(upper.bins)) +
  geom_bar(aes(weight = atoutput)) +
  theme_tufte()

lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 1, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 2, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 3, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 4, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 5, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 6, scales="free_y")
lfplot + facet_wrap_paginate(~time, ncol=4, nrow = 4, page = 7, scales="free_y")

```

So this looks like our best approximation of a true length comp for a particular Atlantis run. Comparisons with standard surveys next.

